#!/bin/bash

# This script compares files in two specified directories based on a generated content hash.
# It identifies files in the 'target' directory (DirectoryB) that have the same content hash
# as any file in the 'reference' directory (DirectoryA) and deletes them from DirectoryB.
# The content hash is generated by processing the file through 'xmlgpx.pl | sort | rhash --sha256 -'.
#
# For gpx track data, a possible (maybe better) alternative to 'xmlgpx.pl' could be to use gpsbabel 
# to extract tracks e.g. 
# gpsbabel -t -i gpx -o garmin_txt /dev/stdin /dev/stdout
# followed by sorting and hashing, or e.g.
# gpsbabel -t -i gpx -o geojson -i gpx -f <file>  - | jq -r '.features[].properties.name' | sort | rhash --sha256 -'.

# --- Argument Parsing and Usage ---
if [ "$#" -ne 2 ]; then
    echo "Usage: $0 <DirectoryA> <DirectoryB>"
    echo "  DirectoryA: The reference directory (files here are KEPT)."
    echo "  DirectoryB: The target directory (files here are DELETED if content matches a file in A)."
    exit 1
fi

# Assign command-line arguments to descriptive variables.
DIR_A="$1"
DIR_B="$2"

# --- Configuration ---
# Set to 0 for a dry run (no files will be deleted), set to 1 to enable actual deletion.
DO_RM=0


# Define the name of the Perl script used for content extraction.
# This script is expected to be in the system's PATH or in the current directory.
PERL_SCRIPT="xmlgpx.pl"

# --- Dependency Checks ---
# Check if the Perl script exists and is executable.
# If not found in PATH, it checks if it's in the current directory and makes it executable.
if ! command -v "$PERL_SCRIPT" &> /dev/null; then
    if [ ! -f "$PERL_SCRIPT" ]; then
        echo "Error: Perl script '$PERL_SCRIPT' not found. Please check its path." >&2
        exit 1
    fi
    # If the script is found in the current directory, prepend './' to ensure it's executed.
    PERL_SCRIPT="./$PERL_SCRIPT"
fi

# Check if the 'rhash' command is available in the system's PATH.
# 'rhash' is essential for generating SHA-256 hashes.
if ! command -v rhash &> /dev/null; then
    echo "Error: 'rhash' command not found. Please install it." >&2
    exit 1
fi

# --- Script Logic ---

# Validate that both provided arguments are existing directories.
if [[ ! -d "$DIR_A" ]]; then
    echo "Error: Directory A not found or is not a directory: $DIR_A"
    exit 1
fi

if [[ ! -d "$DIR_B" ]]; then
    echo "Error: Directory B not found or is not a directory: $DIR_B"
    exit 1
fi

echo "Starting comparison and deletion..."
echo "Reference (A): '$DIR_A'"
echo "Target (B): '$DIR_B'"

# Declare an associative array to store content hashes from Directory A.
# The hash will be the key, and '1' (or any value) will indicate its presence.
declare -A hashes_a

# Function to calculate the content hash of a file
    # The pipeline works as follows:
    # 1. "$PERL_SCRIPT" "$filepath": Executes the Perl script on the file.
    #    This script is expected to extract relevant text content (e.g., GPX track names).
    # 2. | sort: Pipes the output of the Perl script to 'sort'. This ensures that
    #    the order of extracted content does not affect the final hash, making
    #    comparisons robust against minor structural changes (like element order)
    #    in the XML that don't change the logical content.
    # 3. | rhash --sha256 -: Pipes the sorted content to 'rhash' to calculate a SHA-256 hash.
    #    The '-' tells rhash to read from standard input.
    # 4. 2>/dev/null: Redirects any errors from the pipeline (e.g., if xmlgpx.pl fails) to /dev/null.
    # 5. | awk '{print $1}': Extracts only the hash value from rhash's output.
calculate_content_hash() {
    local filepath="$1"
    "$PERL_SCRIPT" "$filepath" | sort | rhash --sha256 - 2>/dev/null | awk '{print $1}'
}

echo "Pre-calculating hashes for files in reference directory (A)..."
# Step 1: Iterate through all regular files in Directory A.
# 'find ... -print0' and 'while IFS= read -r -d $'\0' ...' are used for safe handling of filenames with spaces.
while IFS= read -r -d $'\0' file_a; do
    hash_a=$(calculate_content_hash "$file_a")
    if [ -n "$hash_a" ]; then
        hashes_a["$hash_a"]=1  # Store the hash as a key in the associative array with content "1".
    else
        echo "Warning: Could not generate hash for $file_a. Skipping."
    fi
done < <(find "$DIR_A" -type f -print0)

echo "Found ${#hashes_a[@]} unique content hashes in directory A."

# Step 2: Iterate through all regular files in Directory B.
find "$DIR_B" -type f -print0 | while IFS= read -r -d $'\0' file_b; do
    # Get the content hash of the file in DIR_B
    hash_b=$(calculate_content_hash "$file_b")

    # Skip if hash generation fails
    if [ -z "$hash_b" ]; then
        echo "Warning: Could not generate hash for $file_b. Skipping."
        continue
    fi

    # Step 3: Check if the calculated hash_b exists as a key in the hashes_a array.
    # If it does, it means a file with identical processed content exists in Directory A.
    # In this case, delete the file in Directory B (if variable DO_RM, defined above, is set to 1).
     if [[ -v hashes_a["$hash_b"] ]]; then
        echo "Match found for: $file_b (Hash: $hash_b)"
        if [ "$DO_RM" -eq 1 ]; then
            if rm "$file_b"; then
                echo "-> DELETED $file_b"
            else
                echo "-> Error deleting $file_b"
            fi
        else
            echo "-> DRY RUN: Would have deleted $file_b (set DO_RM=1 to enable deletion)"
        fi
    fi

done

echo "Comparison and deletion complete."
